{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: plotly not installed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as pl\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import keras.layers as kl\n",
    "\n",
    "from polys.keras_layers import CatmullRomLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = CatmullRomLayer(\n",
    "    controls = [np.linspace(-2, 2, 6)],\n",
    "    val_shape = (1,)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  kl.Input(shape = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = l(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs = x, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19802284390>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xxx = np.linspace(-2, 2, 50)\n",
    "pl.plot(xxx, model.predict(xxx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(fun, size):\n",
    "    x = rnd.uniform(low = -2, high = 2, size=100)[:, None]\n",
    "    y = fun(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = np.sin\n",
    "\n",
    "x_train, y_train = generate_data(fun = fun, size = 100)\n",
    "x_test, y_test = generate_data(fun = fun, size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss = \"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples, validate on 100 samples\n",
      "Epoch 1/1000\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6003 - val_loss: 0.5882\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 0s 98us/step - loss: 0.5903 - val_loss: 0.5809\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.5831 - val_loss: 0.5747\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.5767 - val_loss: 0.5688\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.5708 - val_loss: 0.5632\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.5651 - val_loss: 0.5579\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 0.5598 - val_loss: 0.5526\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.5545 - val_loss: 0.5476\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.5493 - val_loss: 0.5424\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.5442 - val_loss: 0.5376\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 0.5393 - val_loss: 0.5328\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.5342 - val_loss: 0.5277\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.5290 - val_loss: 0.5226\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.5240 - val_loss: 0.5177\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.5189 - val_loss: 0.5130\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.5143 - val_loss: 0.5083\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.5097 - val_loss: 0.5039\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.5050 - val_loss: 0.4991\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.5001 - val_loss: 0.4943\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.4952 - val_loss: 0.4896\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.4904 - val_loss: 0.4845\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.4854 - val_loss: 0.4797\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.4806 - val_loss: 0.4752\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.4761 - val_loss: 0.4706\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.4713 - val_loss: 0.4660\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.4666 - val_loss: 0.4614\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.4619 - val_loss: 0.4566\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.4572 - val_loss: 0.4522\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.4527 - val_loss: 0.4477\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.4482 - val_loss: 0.4433\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.4436 - val_loss: 0.4388\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 0.4390 - val_loss: 0.4342\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.4344 - val_loss: 0.4297\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.4298 - val_loss: 0.4254\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.4254 - val_loss: 0.4209\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.4209 - val_loss: 0.4166\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.4165 - val_loss: 0.4123\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.4121 - val_loss: 0.4080\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.4078 - val_loss: 0.4035\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - 0s 52us/step - loss: 0.4034 - val_loss: 0.3995\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.3993 - val_loss: 0.3953\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.3950 - val_loss: 0.3910\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.3907 - val_loss: 0.3868\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.3865 - val_loss: 0.3827\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.3823 - val_loss: 0.3787\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.3781 - val_loss: 0.3745\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.3739 - val_loss: 0.3703\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.3697 - val_loss: 0.3662\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.3656 - val_loss: 0.3622\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.3615 - val_loss: 0.3582\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.3575 - val_loss: 0.3540\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.3534 - val_loss: 0.3501\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.3494 - val_loss: 0.3462\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - 0s 40us/step - loss: 0.3454 - val_loss: 0.3426\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.3416 - val_loss: 0.3387\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.3378 - val_loss: 0.3351\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.3340 - val_loss: 0.3314\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 0.3302 - val_loss: 0.3277\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 0.3265 - val_loss: 0.3237\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.3225 - val_loss: 0.3199\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.3186 - val_loss: 0.3162\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - 0s 51us/step - loss: 0.3149 - val_loss: 0.3123\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3110 - val_loss: 0.3087\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.3073 - val_loss: 0.3049\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.3037 - val_loss: 0.3011\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.2999 - val_loss: 0.2976\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 0.2963 - val_loss: 0.2940\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.2926 - val_loss: 0.2906\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.2891 - val_loss: 0.2871\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.2857 - val_loss: 0.2837\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.2821 - val_loss: 0.2800\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - 0s 122us/step - loss: 0.2785 - val_loss: 0.2765\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.2750 - val_loss: 0.2731\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.2716 - val_loss: 0.2699\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.2683 - val_loss: 0.2666\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.2649 - val_loss: 0.2631\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.2615 - val_loss: 0.2599\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.2581 - val_loss: 0.2567\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 110us/step - loss: 0.2549 - val_loss: 0.2533\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.2516 - val_loss: 0.2500\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.2483 - val_loss: 0.2468\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.2451 - val_loss: 0.2437\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.2420 - val_loss: 0.2408\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 0.2391 - val_loss: 0.2379\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - 0s 129us/step - loss: 0.2361 - val_loss: 0.2348\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.2330 - val_loss: 0.2318\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.2300 - val_loss: 0.2286\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - 0s 102us/step - loss: 0.2268 - val_loss: 0.2255\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.2237 - val_loss: 0.2226\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.2208 - val_loss: 0.2195\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.2178 - val_loss: 0.2165\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.2148 - val_loss: 0.2135\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.2119 - val_loss: 0.2108\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 0.2090 - val_loss: 0.2079\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.2061 - val_loss: 0.2052\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - 0s 126us/step - loss: 0.2033 - val_loss: 0.2024\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 0.2006 - val_loss: 0.1996\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1978 - val_loss: 0.1970\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 0.1950 - val_loss: 0.1942\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - 0s 150us/step - loss: 0.1923 - val_loss: 0.1916\n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1896 - val_loss: 0.1888\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1869 - val_loss: 0.1862\n",
      "Epoch 103/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1842 - val_loss: 0.1836\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1817 - val_loss: 0.1809\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1789 - val_loss: 0.1782\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1764 - val_loss: 0.1758\n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 0.1739 - val_loss: 0.1734\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1714 - val_loss: 0.1711\n",
      "Epoch 109/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1691 - val_loss: 0.1686\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1667 - val_loss: 0.1663\n",
      "Epoch 111/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1644 - val_loss: 0.1641\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1620 - val_loss: 0.1616\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1596 - val_loss: 0.1592\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1572 - val_loss: 0.1570\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1549 - val_loss: 0.1546\n",
      "Epoch 116/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 0.1525 - val_loss: 0.1522\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1503 - val_loss: 0.1501\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1481 - val_loss: 0.1477\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 0.1458 - val_loss: 0.1456\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1436 - val_loss: 0.1435\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - 0s 118us/step - loss: 0.1415 - val_loss: 0.1412\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1392 - val_loss: 0.1390\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.1370 - val_loss: 0.1369\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1349 - val_loss: 0.1350\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1329 - val_loss: 0.1328\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 0.1308 - val_loss: 0.1308\n",
      "Epoch 127/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1287 - val_loss: 0.1286\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1266 - val_loss: 0.1266\n",
      "Epoch 129/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1246 - val_loss: 0.1246\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1226 - val_loss: 0.1226\n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1206 - val_loss: 0.1206\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - 0s 101us/step - loss: 0.1186 - val_loss: 0.1188\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - 0s 116us/step - loss: 0.1168 - val_loss: 0.1169\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1150 - val_loss: 0.1151\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1131 - val_loss: 0.1131\n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1113 - val_loss: 0.1114\n",
      "Epoch 137/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1095 - val_loss: 0.1095\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.1076 - val_loss: 0.1078\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1060 - val_loss: 0.1062\n",
      "Epoch 140/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 0.1042 - val_loss: 0.1043\n",
      "Epoch 141/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1025 - val_loss: 0.1026\n",
      "Epoch 142/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.1007 - val_loss: 0.1008\n",
      "Epoch 143/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.0989 - val_loss: 0.0990\n",
      "Epoch 144/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0971 - val_loss: 0.0971\n",
      "Epoch 145/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0953 - val_loss: 0.0953\n",
      "Epoch 146/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0935 - val_loss: 0.0937\n",
      "Epoch 147/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0919 - val_loss: 0.0919\n",
      "Epoch 148/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0902 - val_loss: 0.0905\n",
      "Epoch 149/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0887 - val_loss: 0.0889\n",
      "Epoch 150/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0871 - val_loss: 0.0874\n",
      "Epoch 151/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0856 - val_loss: 0.0857\n",
      "Epoch 152/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0839 - val_loss: 0.0842\n",
      "Epoch 153/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0824 - val_loss: 0.0827\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0809 - val_loss: 0.0811\n",
      "Epoch 155/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0792 - val_loss: 0.0796\n",
      "Epoch 156/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 70us/step - loss: 0.0777 - val_loss: 0.0780\n",
      "Epoch 157/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0762 - val_loss: 0.0766\n",
      "Epoch 158/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0748 - val_loss: 0.0751\n",
      "Epoch 159/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0733 - val_loss: 0.0736\n",
      "Epoch 160/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0719 - val_loss: 0.0721\n",
      "Epoch 161/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0704 - val_loss: 0.0706\n",
      "Epoch 162/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0689 - val_loss: 0.0690\n",
      "Epoch 163/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0674 - val_loss: 0.0676\n",
      "Epoch 164/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0659 - val_loss: 0.0662\n",
      "Epoch 165/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0646 - val_loss: 0.0648\n",
      "Epoch 166/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0632 - val_loss: 0.0633\n",
      "Epoch 167/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0617 - val_loss: 0.0621\n",
      "Epoch 168/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0604 - val_loss: 0.0606\n",
      "Epoch 169/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0590 - val_loss: 0.0593\n",
      "Epoch 170/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0577 - val_loss: 0.0580\n",
      "Epoch 171/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0564 - val_loss: 0.0567\n",
      "Epoch 172/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0551 - val_loss: 0.0554\n",
      "Epoch 173/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0538 - val_loss: 0.0543\n",
      "Epoch 174/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0527 - val_loss: 0.0531\n",
      "Epoch 175/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0515 - val_loss: 0.0518\n",
      "Epoch 176/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0502 - val_loss: 0.0506\n",
      "Epoch 177/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0490 - val_loss: 0.0493\n",
      "Epoch 178/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0478 - val_loss: 0.0481\n",
      "Epoch 179/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0466 - val_loss: 0.0469\n",
      "Epoch 180/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0455 - val_loss: 0.0458\n",
      "Epoch 181/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 0.0443 - val_loss: 0.0446\n",
      "Epoch 182/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 0.0432 - val_loss: 0.0435\n",
      "Epoch 183/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0421 - val_loss: 0.0423\n",
      "Epoch 184/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0410 - val_loss: 0.0413\n",
      "Epoch 185/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0399 - val_loss: 0.0402\n",
      "Epoch 186/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0388 - val_loss: 0.0391\n",
      "Epoch 187/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0377 - val_loss: 0.0380\n",
      "Epoch 188/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0367 - val_loss: 0.0369\n",
      "Epoch 189/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0356 - val_loss: 0.0360\n",
      "Epoch 190/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0347 - val_loss: 0.0350\n",
      "Epoch 191/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0337 - val_loss: 0.0341\n",
      "Epoch 192/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0328 - val_loss: 0.0331\n",
      "Epoch 193/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0318 - val_loss: 0.0322\n",
      "Epoch 194/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0309 - val_loss: 0.0312\n",
      "Epoch 195/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0300 - val_loss: 0.0303\n",
      "Epoch 196/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 0.0290 - val_loss: 0.0293\n",
      "Epoch 197/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0281 - val_loss: 0.0284\n",
      "Epoch 198/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0272 - val_loss: 0.0275\n",
      "Epoch 199/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 0.0263 - val_loss: 0.0267\n",
      "Epoch 200/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 0.0255 - val_loss: 0.0257\n",
      "Epoch 201/1000\n",
      "100/100 [==============================] - 0s 140us/step - loss: 0.0246 - val_loss: 0.0249\n",
      "Epoch 202/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.0238 - val_loss: 0.0241\n",
      "Epoch 203/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 0.0230 - val_loss: 0.0233\n",
      "Epoch 204/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.0222 - val_loss: 0.0224\n",
      "Epoch 205/1000\n",
      "100/100 [==============================] - 0s 171us/step - loss: 0.0214 - val_loss: 0.0216\n",
      "Epoch 206/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.0206 - val_loss: 0.0208\n",
      "Epoch 207/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.0199 - val_loss: 0.0201\n",
      "Epoch 208/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0191 - val_loss: 0.0195\n",
      "Epoch 209/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0185 - val_loss: 0.0187\n",
      "Epoch 210/1000\n",
      "100/100 [==============================] - 0s 140us/step - loss: 0.0178 - val_loss: 0.0180\n",
      "Epoch 211/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0171 - val_loss: 0.0173\n",
      "Epoch 212/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 0.0164 - val_loss: 0.0167\n",
      "Epoch 213/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 0.0158 - val_loss: 0.0160\n",
      "Epoch 214/1000\n",
      "100/100 [==============================] - 0s 113us/step - loss: 0.0151 - val_loss: 0.0154\n",
      "Epoch 215/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 0.0145 - val_loss: 0.0147\n",
      "Epoch 216/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 217/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 0.0132 - val_loss: 0.0135\n",
      "Epoch 218/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.0126 - val_loss: 0.0129\n",
      "Epoch 219/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0121 - val_loss: 0.0124\n",
      "Epoch 220/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 221/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 222/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 223/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 224/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 225/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 0.0090 - val_loss: 0.0091\n",
      "Epoch 226/1000\n",
      "100/100 [==============================] - 0s 104us/step - loss: 0.0085 - val_loss: 0.0087\n",
      "Epoch 227/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 228/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0076 - val_loss: 0.0078\n",
      "Epoch 229/1000\n",
      "100/100 [==============================] - 0s 113us/step - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 230/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 231/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.0063 - val_loss: 0.0065\n",
      "Epoch 232/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 233/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.0055 - val_loss: 0.0057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 235/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 236/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 237/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 238/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 239/1000\n",
      "100/100 [==============================] - 0s 131us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 240/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 241/1000\n",
      "100/100 [==============================] - 0s 140us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 242/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 243/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 244/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 245/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 246/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 247/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 248/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 249/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 250/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 251/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 252/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 9.2358e-04 - val_loss: 0.0010\n",
      "Epoch 253/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 8.1056e-04 - val_loss: 8.7533e-04\n",
      "Epoch 254/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.0606e-04 - val_loss: 7.7375e-04\n",
      "Epoch 255/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 6.2103e-04 - val_loss: 6.9329e-04\n",
      "Epoch 256/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 5.5308e-04 - val_loss: 6.1547e-04\n",
      "Epoch 257/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 4.8775e-04 - val_loss: 5.3135e-04\n",
      "Epoch 258/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 4.2329e-04 - val_loss: 4.7068e-04\n",
      "Epoch 259/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 3.7271e-04 - val_loss: 4.0007e-04\n",
      "Epoch 260/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 3.2156e-04 - val_loss: 3.5299e-04\n",
      "Epoch 261/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 2.8509e-04 - val_loss: 3.0386e-04\n",
      "Epoch 262/1000\n",
      "100/100 [==============================] - 0s 109us/step - loss: 2.5119e-04 - val_loss: 2.6878e-04\n",
      "Epoch 263/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 2.2760e-04 - val_loss: 2.4068e-04\n",
      "Epoch 264/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 2.0685e-04 - val_loss: 2.0757e-04\n",
      "Epoch 265/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 1.8334e-04 - val_loss: 1.8881e-04\n",
      "Epoch 266/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 1.7130e-04 - val_loss: 1.7281e-04\n",
      "Epoch 267/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 1.5759e-04 - val_loss: 1.5908e-04\n",
      "Epoch 268/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 1.4737e-04 - val_loss: 1.4471e-04\n",
      "Epoch 269/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 1.3714e-04 - val_loss: 1.3766e-04\n",
      "Epoch 270/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 1.3204e-04 - val_loss: 1.2652e-04\n",
      "Epoch 271/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 1.2363e-04 - val_loss: 1.2003e-04\n",
      "Epoch 272/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 1.1590e-04 - val_loss: 1.1392e-04\n",
      "Epoch 273/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 1.0857e-04 - val_loss: 1.0840e-04\n",
      "Epoch 274/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 1.0482e-04 - val_loss: 1.0534e-04\n",
      "Epoch 275/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 9.9503e-05 - val_loss: 1.0097e-04\n",
      "Epoch 276/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 9.3831e-05 - val_loss: 9.8227e-05\n",
      "Epoch 277/1000\n",
      "100/100 [==============================] - 0s 119us/step - loss: 8.9557e-05 - val_loss: 9.7450e-05\n",
      "Epoch 278/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 8.6426e-05 - val_loss: 9.6619e-05\n",
      "Epoch 279/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 8.4010e-05 - val_loss: 9.7280e-05\n",
      "Epoch 280/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 8.1257e-05 - val_loss: 9.9041e-05\n",
      "Epoch 281/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 8.2884e-05 - val_loss: 9.9125e-05\n",
      "Epoch 282/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.7771e-05 - val_loss: 1.0086e-04\n",
      "Epoch 283/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 8.0833e-05 - val_loss: 1.0241e-04\n",
      "Epoch 284/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6288e-05 - val_loss: 1.0505e-04\n",
      "Epoch 285/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5782e-05 - val_loss: 1.0912e-04\n",
      "Epoch 286/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5396e-05 - val_loss: 1.0811e-04\n",
      "Epoch 287/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5235e-05 - val_loss: 1.1127e-04\n",
      "Epoch 288/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5364e-05 - val_loss: 1.1075e-04\n",
      "Epoch 289/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4335e-05 - val_loss: 1.1438e-04\n",
      "Epoch 290/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5610e-05 - val_loss: 1.1488e-04\n",
      "Epoch 291/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5154e-05 - val_loss: 1.1333e-04\n",
      "Epoch 292/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4793e-05 - val_loss: 1.1695e-04\n",
      "Epoch 293/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4334e-05 - val_loss: 1.1365e-04\n",
      "Epoch 294/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4347e-05 - val_loss: 1.1427e-04\n",
      "Epoch 295/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5918e-05 - val_loss: 1.1596e-04\n",
      "Epoch 296/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4751e-05 - val_loss: 1.1495e-04\n",
      "Epoch 297/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.3685e-05 - val_loss: 1.1808e-04\n",
      "Epoch 298/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 7.6009e-05 - val_loss: 1.1385e-04\n",
      "Epoch 299/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4909e-05 - val_loss: 1.1334e-04\n",
      "Epoch 300/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5522e-05 - val_loss: 1.1875e-04\n",
      "Epoch 301/1000\n",
      "100/100 [==============================] - 0s 150us/step - loss: 7.5906e-05 - val_loss: 1.1946e-04\n",
      "Epoch 302/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5186e-05 - val_loss: 1.1564e-04\n",
      "Epoch 303/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4769e-05 - val_loss: 1.1749e-04\n",
      "Epoch 304/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4305e-05 - val_loss: 1.1624e-04\n",
      "Epoch 305/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.3933e-05 - val_loss: 1.1641e-04\n",
      "Epoch 306/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4938e-05 - val_loss: 1.1425e-04\n",
      "Epoch 307/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 90us/step - loss: 7.6041e-05 - val_loss: 1.1169e-04\n",
      "Epoch 308/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5227e-05 - val_loss: 1.1459e-04\n",
      "Epoch 309/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.5999e-05 - val_loss: 1.1471e-04\n",
      "Epoch 310/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4783e-05 - val_loss: 1.1362e-04\n",
      "Epoch 311/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5275e-05 - val_loss: 1.1491e-04\n",
      "Epoch 312/1000\n",
      "100/100 [==============================] - 0s 91us/step - loss: 7.4161e-05 - val_loss: 1.1514e-04\n",
      "Epoch 313/1000\n",
      "100/100 [==============================] - 0s 101us/step - loss: 7.5641e-05 - val_loss: 1.1687e-04\n",
      "Epoch 314/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5127e-05 - val_loss: 1.1627e-04\n",
      "Epoch 315/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.6510e-05 - val_loss: 1.1271e-04\n",
      "Epoch 316/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.6679e-05 - val_loss: 1.1303e-04\n",
      "Epoch 317/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.5654e-05 - val_loss: 1.1447e-04\n",
      "Epoch 318/1000\n",
      "100/100 [==============================] - 0s 98us/step - loss: 7.4326e-05 - val_loss: 1.1232e-04\n",
      "Epoch 319/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4530e-05 - val_loss: 1.1251e-04\n",
      "Epoch 320/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.3993e-05 - val_loss: 1.1290e-04\n",
      "Epoch 321/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4135e-05 - val_loss: 1.1570e-04\n",
      "Epoch 322/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.3745e-05 - val_loss: 1.1341e-04\n",
      "Epoch 323/1000\n",
      "100/100 [==============================] - 0s 112us/step - loss: 7.4730e-05 - val_loss: 1.1426e-04\n",
      "Epoch 324/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4084e-05 - val_loss: 1.1718e-04\n",
      "Epoch 325/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5222e-05 - val_loss: 1.1648e-04\n",
      "Epoch 326/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4117e-05 - val_loss: 1.1700e-04\n",
      "Epoch 327/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5500e-05 - val_loss: 1.1653e-04\n",
      "Epoch 328/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4932e-05 - val_loss: 1.1638e-04\n",
      "Epoch 329/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4372e-05 - val_loss: 1.1868e-04\n",
      "Epoch 330/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6743e-05 - val_loss: 1.1794e-04\n",
      "Epoch 331/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4872e-05 - val_loss: 1.1729e-04\n",
      "Epoch 332/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4611e-05 - val_loss: 1.2003e-04\n",
      "Epoch 333/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5066e-05 - val_loss: 1.2086e-04\n",
      "Epoch 334/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6811e-05 - val_loss: 1.2183e-04\n",
      "Epoch 335/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6837e-05 - val_loss: 1.2004e-04\n",
      "Epoch 336/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5287e-05 - val_loss: 1.1931e-04\n",
      "Epoch 337/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4415e-05 - val_loss: 1.1507e-04\n",
      "Epoch 338/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5879e-05 - val_loss: 1.1655e-04\n",
      "Epoch 339/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.3995e-05 - val_loss: 1.1881e-04\n",
      "Epoch 340/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.3454e-05 - val_loss: 1.1958e-04\n",
      "Epoch 341/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.3962e-05 - val_loss: 1.2160e-04\n",
      "Epoch 342/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4931e-05 - val_loss: 1.1721e-04\n",
      "Epoch 343/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.7524e-05 - val_loss: 1.1906e-04\n",
      "Epoch 344/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4156e-05 - val_loss: 1.1965e-04\n",
      "Epoch 345/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.3958e-05 - val_loss: 1.2043e-04\n",
      "Epoch 346/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5148e-05 - val_loss: 1.1951e-04\n",
      "Epoch 347/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6703e-05 - val_loss: 1.1499e-04\n",
      "Epoch 348/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.3389e-05 - val_loss: 1.1662e-04\n",
      "Epoch 349/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6109e-05 - val_loss: 1.1444e-04\n",
      "Epoch 350/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5441e-05 - val_loss: 1.1449e-04\n",
      "Epoch 351/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4734e-05 - val_loss: 1.1487e-04\n",
      "Epoch 352/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5545e-05 - val_loss: 1.1783e-04\n",
      "Epoch 353/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5037e-05 - val_loss: 1.1842e-04\n",
      "Epoch 354/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5380e-05 - val_loss: 1.1480e-04\n",
      "Epoch 355/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5401e-05 - val_loss: 1.1563e-04\n",
      "Epoch 356/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 7.5082e-05 - val_loss: 1.1728e-04\n",
      "Epoch 357/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5410e-05 - val_loss: 1.1856e-04\n",
      "Epoch 358/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 7.5417e-05 - val_loss: 1.1868e-04\n",
      "Epoch 359/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4472e-05 - val_loss: 1.1813e-04\n",
      "Epoch 360/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5680e-05 - val_loss: 1.1662e-04\n",
      "Epoch 361/1000\n",
      "100/100 [==============================] - 0s 109us/step - loss: 7.4085e-05 - val_loss: 1.1598e-04\n",
      "Epoch 362/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4518e-05 - val_loss: 1.1420e-04\n",
      "Epoch 363/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5322e-05 - val_loss: 1.1845e-04\n",
      "Epoch 364/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5183e-05 - val_loss: 1.2013e-04\n",
      "Epoch 365/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5863e-05 - val_loss: 1.2188e-04\n",
      "Epoch 366/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5260e-05 - val_loss: 1.1902e-04\n",
      "Epoch 367/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4734e-05 - val_loss: 1.1941e-04\n",
      "Epoch 368/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4184e-05 - val_loss: 1.1986e-04\n",
      "Epoch 369/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 7.4674e-05 - val_loss: 1.1738e-04\n",
      "Epoch 370/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.7147e-05 - val_loss: 1.1992e-04\n",
      "Epoch 371/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5806e-05 - val_loss: 1.1486e-04\n",
      "Epoch 372/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 7.3471e-05 - val_loss: 1.1574e-04\n",
      "Epoch 373/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5112e-05 - val_loss: 1.1761e-04\n",
      "Epoch 374/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4039e-05 - val_loss: 1.1864e-04\n",
      "Epoch 375/1000\n",
      "100/100 [==============================] - 0s 140us/step - loss: 7.4255e-05 - val_loss: 1.1986e-04\n",
      "Epoch 376/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5286e-05 - val_loss: 1.1924e-04\n",
      "Epoch 377/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4265e-05 - val_loss: 1.2148e-04\n",
      "Epoch 378/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4480e-05 - val_loss: 1.2303e-04\n",
      "Epoch 379/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 70us/step - loss: 7.5534e-05 - val_loss: 1.2177e-04\n",
      "Epoch 380/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.8975e-05 - val_loss: 1.1863e-04\n",
      "Epoch 381/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5945e-05 - val_loss: 1.1482e-04\n",
      "Epoch 382/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5016e-05 - val_loss: 1.1511e-04\n",
      "Epoch 383/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4233e-05 - val_loss: 1.1280e-04\n",
      "Epoch 384/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5806e-05 - val_loss: 1.1680e-04\n",
      "Epoch 385/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4693e-05 - val_loss: 1.1296e-04\n",
      "Epoch 386/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4682e-05 - val_loss: 1.1586e-04\n",
      "Epoch 387/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.5920e-05 - val_loss: 1.1522e-04\n",
      "Epoch 388/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4613e-05 - val_loss: 1.1685e-04\n",
      "Epoch 389/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 7.4449e-05 - val_loss: 1.1710e-04\n",
      "Epoch 390/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 7.4060e-05 - val_loss: 1.1814e-04\n",
      "Epoch 391/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.5529e-05 - val_loss: 1.1707e-04\n",
      "Epoch 392/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4184e-05 - val_loss: 1.1436e-04\n",
      "Epoch 393/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4324e-05 - val_loss: 1.1666e-04\n",
      "Epoch 394/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5811e-05 - val_loss: 1.1649e-04\n",
      "Epoch 395/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.5133e-05 - val_loss: 1.1846e-04\n",
      "Epoch 396/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4189e-05 - val_loss: 1.1765e-04\n",
      "Epoch 397/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.7412e-05 - val_loss: 1.1952e-04\n",
      "Epoch 398/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.6785e-05 - val_loss: 1.1922e-04\n",
      "Epoch 399/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4412e-05 - val_loss: 1.1795e-04\n",
      "Epoch 400/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.6566e-05 - val_loss: 1.1637e-04\n",
      "Epoch 401/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4454e-05 - val_loss: 1.1630e-04\n",
      "Epoch 402/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.7712e-05 - val_loss: 1.1629e-04\n",
      "Epoch 403/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.6305e-05 - val_loss: 1.1854e-04\n",
      "Epoch 404/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4575e-05 - val_loss: 1.1499e-04\n",
      "Epoch 405/1000\n",
      "100/100 [==============================] - 0s 82us/step - loss: 7.6275e-05 - val_loss: 1.1614e-04\n",
      "Epoch 406/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4880e-05 - val_loss: 1.1564e-04\n",
      "Epoch 407/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 7.4244e-05 - val_loss: 1.1904e-04\n",
      "Epoch 408/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4263e-05 - val_loss: 1.1613e-04\n",
      "Epoch 409/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4503e-05 - val_loss: 1.1414e-04\n",
      "Epoch 410/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5647e-05 - val_loss: 1.1278e-04\n",
      "Epoch 411/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.6196e-05 - val_loss: 1.1133e-04\n",
      "Epoch 412/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 7.4081e-05 - val_loss: 1.1217e-04\n",
      "Epoch 413/1000\n",
      "100/100 [==============================] - 0s 77us/step - loss: 7.5684e-05 - val_loss: 1.1354e-04\n",
      "Epoch 414/1000\n",
      "100/100 [==============================] - 0s 119us/step - loss: 7.4976e-05 - val_loss: 1.1315e-04\n",
      "Epoch 415/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4140e-05 - val_loss: 1.1535e-04\n",
      "Epoch 416/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4992e-05 - val_loss: 1.1498e-04\n",
      "Epoch 417/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4052e-05 - val_loss: 1.1214e-04\n",
      "Epoch 418/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4282e-05 - val_loss: 1.1452e-04\n",
      "Epoch 419/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4979e-05 - val_loss: 1.1365e-04\n",
      "Epoch 420/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.7284e-05 - val_loss: 1.1367e-04\n",
      "Epoch 421/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5209e-05 - val_loss: 1.1658e-04\n",
      "Epoch 422/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4155e-05 - val_loss: 1.2020e-04\n",
      "Epoch 423/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5577e-05 - val_loss: 1.1864e-04\n",
      "Epoch 424/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5173e-05 - val_loss: 1.1919e-04\n",
      "Epoch 425/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4893e-05 - val_loss: 1.2035e-04\n",
      "Epoch 426/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.5419e-05 - val_loss: 1.1926e-04\n",
      "Epoch 427/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 7.4223e-05 - val_loss: 1.2126e-04\n",
      "Epoch 428/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.6370e-05 - val_loss: 1.2076e-04\n",
      "Epoch 429/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5483e-05 - val_loss: 1.2286e-04\n",
      "Epoch 430/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5820e-05 - val_loss: 1.1583e-04\n",
      "Epoch 431/1000\n",
      "100/100 [==============================] - 0s 112us/step - loss: 7.4652e-05 - val_loss: 1.1335e-04\n",
      "Epoch 432/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4212e-05 - val_loss: 1.1400e-04\n",
      "Epoch 433/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6252e-05 - val_loss: 1.1469e-04\n",
      "Epoch 434/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.3845e-05 - val_loss: 1.1443e-04\n",
      "Epoch 435/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5899e-05 - val_loss: 1.1302e-04\n",
      "Epoch 436/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4199e-05 - val_loss: 1.1372e-04\n",
      "Epoch 437/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5001e-05 - val_loss: 1.1884e-04\n",
      "Epoch 438/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5855e-05 - val_loss: 1.2122e-04\n",
      "Epoch 439/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5899e-05 - val_loss: 1.1684e-04\n",
      "Epoch 440/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5308e-05 - val_loss: 1.1895e-04\n",
      "Epoch 441/1000\n",
      "100/100 [==============================] - 0s 116us/step - loss: 7.4499e-05 - val_loss: 1.1887e-04\n",
      "Epoch 442/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5270e-05 - val_loss: 1.1708e-04\n",
      "Epoch 443/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4715e-05 - val_loss: 1.2038e-04\n",
      "Epoch 444/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5311e-05 - val_loss: 1.1942e-04\n",
      "Epoch 445/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4566e-05 - val_loss: 1.1838e-04\n",
      "Epoch 446/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4909e-05 - val_loss: 1.1728e-04\n",
      "Epoch 447/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5801e-05 - val_loss: 1.1848e-04\n",
      "Epoch 448/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 7.4718e-05 - val_loss: 1.1695e-04\n",
      "Epoch 449/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4424e-05 - val_loss: 1.1522e-04\n",
      "Epoch 450/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6366e-05 - val_loss: 1.1570e-04\n",
      "Epoch 451/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 110us/step - loss: 7.6306e-05 - val_loss: 1.1301e-04\n",
      "Epoch 452/1000\n",
      "100/100 [==============================] - 0s 101us/step - loss: 7.4901e-05 - val_loss: 1.1448e-04\n",
      "Epoch 453/1000\n",
      "100/100 [==============================] - 0s 119us/step - loss: 7.5033e-05 - val_loss: 1.1427e-04\n",
      "Epoch 454/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5355e-05 - val_loss: 1.1458e-04\n",
      "Epoch 455/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.3522e-05 - val_loss: 1.1440e-04\n",
      "Epoch 456/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4482e-05 - val_loss: 1.1732e-04\n",
      "Epoch 457/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6635e-05 - val_loss: 1.1736e-04\n",
      "Epoch 458/1000\n",
      "100/100 [==============================] - 0s 122us/step - loss: 7.6464e-05 - val_loss: 1.1738e-04\n",
      "Epoch 459/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5299e-05 - val_loss: 1.1880e-04\n",
      "Epoch 460/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4910e-05 - val_loss: 1.1811e-04\n",
      "Epoch 461/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6619e-05 - val_loss: 1.1425e-04\n",
      "Epoch 462/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4676e-05 - val_loss: 1.1739e-04\n",
      "Epoch 463/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4881e-05 - val_loss: 1.1611e-04\n",
      "Epoch 464/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5874e-05 - val_loss: 1.1624e-04\n",
      "Epoch 465/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4038e-05 - val_loss: 1.1435e-04\n",
      "Epoch 466/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4818e-05 - val_loss: 1.1442e-04\n",
      "Epoch 467/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4873e-05 - val_loss: 1.1125e-04\n",
      "Epoch 468/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4399e-05 - val_loss: 1.1309e-04\n",
      "Epoch 469/1000\n",
      "100/100 [==============================] - 0s 118us/step - loss: 7.5644e-05 - val_loss: 1.1413e-04\n",
      "Epoch 470/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6504e-05 - val_loss: 1.1285e-04\n",
      "Epoch 471/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 7.4801e-05 - val_loss: 1.1258e-04\n",
      "Epoch 472/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5449e-05 - val_loss: 1.1351e-04\n",
      "Epoch 473/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4025e-05 - val_loss: 1.1524e-04\n",
      "Epoch 474/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.6087e-05 - val_loss: 1.1130e-04\n",
      "Epoch 475/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4788e-05 - val_loss: 1.1189e-04\n",
      "Epoch 476/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4790e-05 - val_loss: 1.1385e-04\n",
      "Epoch 477/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4372e-05 - val_loss: 1.1322e-04\n",
      "Epoch 478/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5350e-05 - val_loss: 1.1040e-04\n",
      "Epoch 479/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.5057e-05 - val_loss: 1.1158e-04\n",
      "Epoch 480/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.3816e-05 - val_loss: 1.1252e-04\n",
      "Epoch 481/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4907e-05 - val_loss: 1.1562e-04\n",
      "Epoch 482/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4972e-05 - val_loss: 1.1605e-04\n",
      "Epoch 483/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.3762e-05 - val_loss: 1.1328e-04\n",
      "Epoch 484/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 7.4660e-05 - val_loss: 1.1666e-04\n",
      "Epoch 485/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5262e-05 - val_loss: 1.1911e-04\n",
      "Epoch 486/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.5519e-05 - val_loss: 1.1847e-04\n",
      "Epoch 487/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 7.6435e-05 - val_loss: 1.1946e-04\n",
      "Epoch 488/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.5219e-05 - val_loss: 1.2109e-04\n",
      "Epoch 489/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.5699e-05 - val_loss: 1.2151e-04\n",
      "Epoch 490/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5168e-05 - val_loss: 1.1823e-04\n",
      "Epoch 491/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4299e-05 - val_loss: 1.1735e-04\n",
      "Epoch 492/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4390e-05 - val_loss: 1.1902e-04\n",
      "Epoch 493/1000\n",
      "100/100 [==============================] - 0s 59us/step - loss: 7.4881e-05 - val_loss: 1.1734e-04\n",
      "Epoch 494/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.5888e-05 - val_loss: 1.1751e-04\n",
      "Epoch 495/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4427e-05 - val_loss: 1.1683e-04\n",
      "Epoch 496/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4821e-05 - val_loss: 1.1572e-04\n",
      "Epoch 497/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.7795e-05 - val_loss: 1.1683e-04\n",
      "Epoch 498/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 7.4867e-05 - val_loss: 1.1749e-04\n",
      "Epoch 499/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4785e-05 - val_loss: 1.1687e-04\n",
      "Epoch 500/1000\n",
      "100/100 [==============================] - 0s 61us/step - loss: 7.4244e-05 - val_loss: 1.1743e-04\n",
      "Epoch 501/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 7.4192e-05 - val_loss: 1.2010e-04\n",
      "Epoch 502/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4281e-05 - val_loss: 1.1899e-04\n",
      "Epoch 503/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4136e-05 - val_loss: 1.1981e-04\n",
      "Epoch 504/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4629e-05 - val_loss: 1.1802e-04\n",
      "Epoch 505/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.5067e-05 - val_loss: 1.1688e-04\n",
      "Epoch 506/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4747e-05 - val_loss: 1.1650e-04\n",
      "Epoch 507/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5284e-05 - val_loss: 1.1808e-04\n",
      "Epoch 508/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 7.5020e-05 - val_loss: 1.2056e-04\n",
      "Epoch 509/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.5526e-05 - val_loss: 1.2019e-04\n",
      "Epoch 510/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 7.3719e-05 - val_loss: 1.2000e-04\n",
      "Epoch 511/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 7.4467e-05 - val_loss: 1.1974e-04\n",
      "Epoch 512/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.7326e-05 - val_loss: 1.1722e-04\n",
      "Epoch 513/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.5122e-05 - val_loss: 1.1308e-04\n",
      "Epoch 514/1000\n",
      "100/100 [==============================] - 0s 56us/step - loss: 7.5849e-05 - val_loss: 1.1477e-04\n",
      "Epoch 515/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4967e-05 - val_loss: 1.1400e-04\n",
      "Epoch 516/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4671e-05 - val_loss: 1.1264e-04\n",
      "Epoch 517/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4061e-05 - val_loss: 1.1359e-04\n",
      "Epoch 518/1000\n",
      "100/100 [==============================] - 0s 50us/step - loss: 7.5566e-05 - val_loss: 1.1453e-04\n",
      "Epoch 519/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 7.4565e-05 - val_loss: 1.1462e-04\n",
      "Epoch 520/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4317e-05 - val_loss: 1.1800e-04\n",
      "Epoch 521/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4358e-05 - val_loss: 1.2065e-04\n",
      "Epoch 522/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4211e-05 - val_loss: 1.1724e-04\n",
      "Epoch 523/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 110us/step - loss: 7.3627e-05 - val_loss: 1.1452e-04\n",
      "Epoch 524/1000\n",
      "100/100 [==============================] - 0s 113us/step - loss: 7.4266e-05 - val_loss: 1.1673e-04\n",
      "Epoch 525/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5309e-05 - val_loss: 1.1582e-04\n",
      "Epoch 526/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5113e-05 - val_loss: 1.1844e-04\n",
      "Epoch 527/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 7.5487e-05 - val_loss: 1.1460e-04\n",
      "Epoch 528/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6809e-05 - val_loss: 1.1333e-04\n",
      "Epoch 529/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5113e-05 - val_loss: 1.1425e-04\n",
      "Epoch 530/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5737e-05 - val_loss: 1.1876e-04\n",
      "Epoch 531/1000\n",
      "100/100 [==============================] - 0s 116us/step - loss: 7.4385e-05 - val_loss: 1.1988e-04\n",
      "Epoch 532/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 7.3845e-05 - val_loss: 1.2122e-04\n",
      "Epoch 533/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5226e-05 - val_loss: 1.2085e-04\n",
      "Epoch 534/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5305e-05 - val_loss: 1.2007e-04\n",
      "Epoch 535/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4747e-05 - val_loss: 1.2257e-04\n",
      "Epoch 536/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6755e-05 - val_loss: 1.1745e-04\n",
      "Epoch 537/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4409e-05 - val_loss: 1.1795e-04\n",
      "Epoch 538/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5818e-05 - val_loss: 1.1862e-04\n",
      "Epoch 539/1000\n",
      "100/100 [==============================] - 0s 117us/step - loss: 7.5221e-05 - val_loss: 1.1976e-04\n",
      "Epoch 540/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4807e-05 - val_loss: 1.2085e-04\n",
      "Epoch 541/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4290e-05 - val_loss: 1.1784e-04\n",
      "Epoch 542/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5009e-05 - val_loss: 1.1688e-04\n",
      "Epoch 543/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4768e-05 - val_loss: 1.1349e-04\n",
      "Epoch 544/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4823e-05 - val_loss: 1.1506e-04\n",
      "Epoch 545/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6852e-05 - val_loss: 1.1472e-04\n",
      "Epoch 546/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.7876e-05 - val_loss: 1.1284e-04\n",
      "Epoch 547/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 7.4889e-05 - val_loss: 1.1382e-04\n",
      "Epoch 548/1000\n",
      "100/100 [==============================] - 0s 105us/step - loss: 7.4774e-05 - val_loss: 1.1435e-04\n",
      "Epoch 549/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4144e-05 - val_loss: 1.1468e-04\n",
      "Epoch 550/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4910e-05 - val_loss: 1.1455e-04\n",
      "Epoch 551/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6127e-05 - val_loss: 1.1623e-04\n",
      "Epoch 552/1000\n",
      "100/100 [==============================] - 0s 114us/step - loss: 7.4502e-05 - val_loss: 1.1616e-04\n",
      "Epoch 553/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4448e-05 - val_loss: 1.1371e-04\n",
      "Epoch 554/1000\n",
      "100/100 [==============================] - 0s 123us/step - loss: 7.5280e-05 - val_loss: 1.1555e-04\n",
      "Epoch 555/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4536e-05 - val_loss: 1.1472e-04\n",
      "Epoch 556/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6044e-05 - val_loss: 1.1362e-04\n",
      "Epoch 557/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5094e-05 - val_loss: 1.1261e-04\n",
      "Epoch 558/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4874e-05 - val_loss: 1.1180e-04\n",
      "Epoch 559/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4500e-05 - val_loss: 1.1287e-04\n",
      "Epoch 560/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5202e-05 - val_loss: 1.1281e-04\n",
      "Epoch 561/1000\n",
      "100/100 [==============================] - 0s 113us/step - loss: 7.6468e-05 - val_loss: 1.1422e-04\n",
      "Epoch 562/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4636e-05 - val_loss: 1.1346e-04\n",
      "Epoch 563/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4822e-05 - val_loss: 1.1491e-04\n",
      "Epoch 564/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6477e-05 - val_loss: 1.1742e-04\n",
      "Epoch 565/1000\n",
      "100/100 [==============================] - 0s 113us/step - loss: 7.5717e-05 - val_loss: 1.1883e-04\n",
      "Epoch 566/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4819e-05 - val_loss: 1.1870e-04\n",
      "Epoch 567/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 7.4424e-05 - val_loss: 1.1748e-04\n",
      "Epoch 568/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6627e-05 - val_loss: 1.1974e-04\n",
      "Epoch 569/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 7.5173e-05 - val_loss: 1.1418e-04\n",
      "Epoch 570/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4255e-05 - val_loss: 1.1722e-04\n",
      "Epoch 571/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4447e-05 - val_loss: 1.1927e-04\n",
      "Epoch 572/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5418e-05 - val_loss: 1.1877e-04\n",
      "Epoch 573/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5905e-05 - val_loss: 1.1920e-04\n",
      "Epoch 574/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5892e-05 - val_loss: 1.1592e-04\n",
      "Epoch 575/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4813e-05 - val_loss: 1.1761e-04\n",
      "Epoch 576/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5058e-05 - val_loss: 1.1636e-04\n",
      "Epoch 577/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4014e-05 - val_loss: 1.1625e-04\n",
      "Epoch 578/1000\n",
      "100/100 [==============================] - 0s 140us/step - loss: 7.4134e-05 - val_loss: 1.1677e-04\n",
      "Epoch 579/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.3878e-05 - val_loss: 1.1659e-04\n",
      "Epoch 580/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4813e-05 - val_loss: 1.1584e-04\n",
      "Epoch 581/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.3773e-05 - val_loss: 1.1735e-04\n",
      "Epoch 582/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.5537e-05 - val_loss: 1.1810e-04\n",
      "Epoch 583/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4342e-05 - val_loss: 1.1933e-04\n",
      "Epoch 584/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4345e-05 - val_loss: 1.1732e-04\n",
      "Epoch 585/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4659e-05 - val_loss: 1.1788e-04\n",
      "Epoch 586/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5689e-05 - val_loss: 1.1291e-04\n",
      "Epoch 587/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4239e-05 - val_loss: 1.1407e-04\n",
      "Epoch 588/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4406e-05 - val_loss: 1.1644e-04\n",
      "Epoch 589/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.6103e-05 - val_loss: 1.1168e-04\n",
      "Epoch 590/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.3263e-05 - val_loss: 1.1280e-04\n",
      "Epoch 591/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4276e-05 - val_loss: 1.1578e-04\n",
      "Epoch 592/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.6637e-05 - val_loss: 1.1566e-04\n",
      "Epoch 593/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5199e-05 - val_loss: 1.1559e-04\n",
      "Epoch 594/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.5602e-05 - val_loss: 1.1561e-04\n",
      "Epoch 595/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 70us/step - loss: 7.5435e-05 - val_loss: 1.1530e-04\n",
      "Epoch 596/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5706e-05 - val_loss: 1.1557e-04\n",
      "Epoch 597/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5411e-05 - val_loss: 1.1748e-04\n",
      "Epoch 598/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4525e-05 - val_loss: 1.1830e-04\n",
      "Epoch 599/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 7.3902e-05 - val_loss: 1.2023e-04\n",
      "Epoch 600/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4036e-05 - val_loss: 1.2111e-04\n",
      "Epoch 601/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.6222e-05 - val_loss: 1.1619e-04\n",
      "Epoch 602/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 7.6228e-05 - val_loss: 1.1751e-04\n",
      "Epoch 603/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.5566e-05 - val_loss: 1.1509e-04\n",
      "Epoch 604/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 7.6401e-05 - val_loss: 1.1539e-04\n",
      "Epoch 605/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 7.5393e-05 - val_loss: 1.1602e-04\n",
      "Epoch 606/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.5189e-05 - val_loss: 1.1669e-04\n",
      "Epoch 607/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.3932e-05 - val_loss: 1.1591e-04\n",
      "Epoch 608/1000\n",
      "100/100 [==============================] - 0s 91us/step - loss: 7.3701e-05 - val_loss: 1.1611e-04\n",
      "Epoch 609/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4358e-05 - val_loss: 1.1787e-04\n",
      "Epoch 610/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5254e-05 - val_loss: 1.1427e-04\n",
      "Epoch 611/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.5022e-05 - val_loss: 1.1467e-04\n",
      "Epoch 612/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.6505e-05 - val_loss: 1.1572e-04\n",
      "Epoch 613/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4311e-05 - val_loss: 1.1367e-04\n",
      "Epoch 614/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4029e-05 - val_loss: 1.1634e-04\n",
      "Epoch 615/1000\n",
      "100/100 [==============================] - 0s 91us/step - loss: 7.4982e-05 - val_loss: 1.1741e-04\n",
      "Epoch 616/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5580e-05 - val_loss: 1.2048e-04\n",
      "Epoch 617/1000\n",
      "100/100 [==============================] - 0s 91us/step - loss: 7.3667e-05 - val_loss: 1.1682e-04\n",
      "Epoch 618/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4060e-05 - val_loss: 1.1249e-04\n",
      "Epoch 619/1000\n",
      "100/100 [==============================] - 0s 84us/step - loss: 7.5425e-05 - val_loss: 1.1314e-04\n",
      "Epoch 620/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.5603e-05 - val_loss: 1.1085e-04\n",
      "Epoch 621/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.3969e-05 - val_loss: 1.1335e-04\n",
      "Epoch 622/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5189e-05 - val_loss: 1.1268e-04\n",
      "Epoch 623/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5214e-05 - val_loss: 1.1359e-04\n",
      "Epoch 624/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5324e-05 - val_loss: 1.1375e-04\n",
      "Epoch 625/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5862e-05 - val_loss: 1.1166e-04\n",
      "Epoch 626/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4680e-05 - val_loss: 1.1380e-04\n",
      "Epoch 627/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4465e-05 - val_loss: 1.1543e-04\n",
      "Epoch 628/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4424e-05 - val_loss: 1.1756e-04\n",
      "Epoch 629/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6720e-05 - val_loss: 1.1337e-04\n",
      "Epoch 630/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5919e-05 - val_loss: 1.1124e-04\n",
      "Epoch 631/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 7.5491e-05 - val_loss: 1.1135e-04\n",
      "Epoch 632/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4486e-05 - val_loss: 1.1517e-04\n",
      "Epoch 633/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4430e-05 - val_loss: 1.1761e-04\n",
      "Epoch 634/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6736e-05 - val_loss: 1.1375e-04\n",
      "Epoch 635/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4704e-05 - val_loss: 1.1245e-04\n",
      "Epoch 636/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4666e-05 - val_loss: 1.1558e-04\n",
      "Epoch 637/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5376e-05 - val_loss: 1.1438e-04\n",
      "Epoch 638/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4148e-05 - val_loss: 1.1167e-04\n",
      "Epoch 639/1000\n",
      "100/100 [==============================] - 0s 122us/step - loss: 7.3839e-05 - val_loss: 1.1357e-04\n",
      "Epoch 640/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.6210e-05 - val_loss: 1.1376e-04\n",
      "Epoch 641/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4843e-05 - val_loss: 1.1312e-04\n",
      "Epoch 642/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.3662e-05 - val_loss: 1.1638e-04\n",
      "Epoch 643/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5312e-05 - val_loss: 1.1437e-04\n",
      "Epoch 644/1000\n",
      "100/100 [==============================] - 0s 118us/step - loss: 7.5209e-05 - val_loss: 1.1303e-04\n",
      "Epoch 645/1000\n",
      "100/100 [==============================] - 0s 109us/step - loss: 7.5248e-05 - val_loss: 1.1646e-04\n",
      "Epoch 646/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5446e-05 - val_loss: 1.1564e-04\n",
      "Epoch 647/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.6064e-05 - val_loss: 1.1405e-04\n",
      "Epoch 648/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5104e-05 - val_loss: 1.1408e-04\n",
      "Epoch 649/1000\n",
      "100/100 [==============================] - 0s 133us/step - loss: 7.4660e-05 - val_loss: 1.1693e-04\n",
      "Epoch 650/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4963e-05 - val_loss: 1.1463e-04\n",
      "Epoch 651/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.3668e-05 - val_loss: 1.1514e-04\n",
      "Epoch 652/1000\n",
      "100/100 [==============================] - 0s 103us/step - loss: 7.5058e-05 - val_loss: 1.1664e-04\n",
      "Epoch 653/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4994e-05 - val_loss: 1.1792e-04\n",
      "Epoch 654/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5843e-05 - val_loss: 1.2007e-04\n",
      "Epoch 655/1000\n",
      "100/100 [==============================] - 0s 128us/step - loss: 7.5730e-05 - val_loss: 1.1675e-04\n",
      "Epoch 656/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4591e-05 - val_loss: 1.1460e-04\n",
      "Epoch 657/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4700e-05 - val_loss: 1.1414e-04\n",
      "Epoch 658/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 7.5751e-05 - val_loss: 1.1361e-04\n",
      "Epoch 659/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5043e-05 - val_loss: 1.1264e-04\n",
      "Epoch 660/1000\n",
      "100/100 [==============================] - 0s 101us/step - loss: 7.5143e-05 - val_loss: 1.1320e-04\n",
      "Epoch 661/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.7508e-05 - val_loss: 1.1540e-04\n",
      "Epoch 662/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5756e-05 - val_loss: 1.1454e-04\n",
      "Epoch 663/1000\n",
      "100/100 [==============================] - 0s 119us/step - loss: 7.5101e-05 - val_loss: 1.1351e-04\n",
      "Epoch 664/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4925e-05 - val_loss: 1.1349e-04\n",
      "Epoch 665/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.3945e-05 - val_loss: 1.1424e-04\n",
      "Epoch 666/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.6150e-05 - val_loss: 1.1618e-04\n",
      "Epoch 667/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 131us/step - loss: 7.4213e-05 - val_loss: 1.1724e-04\n",
      "Epoch 668/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4190e-05 - val_loss: 1.1796e-04\n",
      "Epoch 669/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5673e-05 - val_loss: 1.1809e-04\n",
      "Epoch 670/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5429e-05 - val_loss: 1.2034e-04\n",
      "Epoch 671/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.3912e-05 - val_loss: 1.1532e-04\n",
      "Epoch 672/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.3555e-05 - val_loss: 1.1574e-04\n",
      "Epoch 673/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5481e-05 - val_loss: 1.1686e-04\n",
      "Epoch 674/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5335e-05 - val_loss: 1.1572e-04\n",
      "Epoch 675/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6472e-05 - val_loss: 1.1690e-04\n",
      "Epoch 676/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.6169e-05 - val_loss: 1.1555e-04\n",
      "Epoch 677/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5655e-05 - val_loss: 1.1789e-04\n",
      "Epoch 678/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6327e-05 - val_loss: 1.2024e-04\n",
      "Epoch 679/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4590e-05 - val_loss: 1.1632e-04\n",
      "Epoch 680/1000\n",
      "100/100 [==============================] - 0s 150us/step - loss: 7.4880e-05 - val_loss: 1.1601e-04\n",
      "Epoch 681/1000\n",
      "100/100 [==============================] - 0s 140us/step - loss: 7.5741e-05 - val_loss: 1.1679e-04\n",
      "Epoch 682/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5768e-05 - val_loss: 1.1657e-04\n",
      "Epoch 683/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.5133e-05 - val_loss: 1.1722e-04\n",
      "Epoch 684/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.5044e-05 - val_loss: 1.2026e-04\n",
      "Epoch 685/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.6052e-05 - val_loss: 1.2005e-04\n",
      "Epoch 686/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4281e-05 - val_loss: 1.1542e-04\n",
      "Epoch 687/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.5079e-05 - val_loss: 1.1483e-04\n",
      "Epoch 688/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5324e-05 - val_loss: 1.1593e-04\n",
      "Epoch 689/1000\n",
      "100/100 [==============================] - 0s 83us/step - loss: 7.4351e-05 - val_loss: 1.1726e-04\n",
      "Epoch 690/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4835e-05 - val_loss: 1.1603e-04\n",
      "Epoch 691/1000\n",
      "100/100 [==============================] - 0s 91us/step - loss: 7.3806e-05 - val_loss: 1.1851e-04\n",
      "Epoch 692/1000\n",
      "100/100 [==============================] - 0s 113us/step - loss: 7.4535e-05 - val_loss: 1.1958e-04\n",
      "Epoch 693/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4803e-05 - val_loss: 1.1837e-04\n",
      "Epoch 694/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4468e-05 - val_loss: 1.1597e-04\n",
      "Epoch 695/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.3592e-05 - val_loss: 1.1604e-04\n",
      "Epoch 696/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4677e-05 - val_loss: 1.1781e-04\n",
      "Epoch 697/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.3726e-05 - val_loss: 1.1735e-04\n",
      "Epoch 698/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4530e-05 - val_loss: 1.1598e-04\n",
      "Epoch 699/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5234e-05 - val_loss: 1.1806e-04\n",
      "Epoch 700/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4400e-05 - val_loss: 1.1759e-04\n",
      "Epoch 701/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4655e-05 - val_loss: 1.1810e-04\n",
      "Epoch 702/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4967e-05 - val_loss: 1.1972e-04\n",
      "Epoch 703/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4981e-05 - val_loss: 1.1605e-04\n",
      "Epoch 704/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4301e-05 - val_loss: 1.1408e-04\n",
      "Epoch 705/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 7.5864e-05 - val_loss: 1.1425e-04\n",
      "Epoch 706/1000\n",
      "100/100 [==============================] - 0s 140us/step - loss: 7.4397e-05 - val_loss: 1.1523e-04\n",
      "Epoch 707/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4415e-05 - val_loss: 1.1426e-04\n",
      "Epoch 708/1000\n",
      "100/100 [==============================] - 0s 119us/step - loss: 7.4726e-05 - val_loss: 1.1713e-04\n",
      "Epoch 709/1000\n",
      "100/100 [==============================] - 0s 105us/step - loss: 7.4030e-05 - val_loss: 1.1822e-04\n",
      "Epoch 710/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4552e-05 - val_loss: 1.1838e-04\n",
      "Epoch 711/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5305e-05 - val_loss: 1.2106e-04\n",
      "Epoch 712/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5105e-05 - val_loss: 1.2117e-04\n",
      "Epoch 713/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4331e-05 - val_loss: 1.1952e-04\n",
      "Epoch 714/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5242e-05 - val_loss: 1.1834e-04\n",
      "Epoch 715/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6313e-05 - val_loss: 1.2044e-04\n",
      "Epoch 716/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5519e-05 - val_loss: 1.2088e-04\n",
      "Epoch 717/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5916e-05 - val_loss: 1.1714e-04\n",
      "Epoch 718/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.7542e-05 - val_loss: 1.1870e-04\n",
      "Epoch 719/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4988e-05 - val_loss: 1.1644e-04\n",
      "Epoch 720/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4190e-05 - val_loss: 1.1915e-04\n",
      "Epoch 721/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.6294e-05 - val_loss: 1.1844e-04\n",
      "Epoch 722/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4600e-05 - val_loss: 1.1660e-04\n",
      "Epoch 723/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 7.4909e-05 - val_loss: 1.1960e-04\n",
      "Epoch 724/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4787e-05 - val_loss: 1.1890e-04\n",
      "Epoch 725/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.6185e-05 - val_loss: 1.2316e-04\n",
      "Epoch 726/1000\n",
      "100/100 [==============================] - 0s 62us/step - loss: 7.3954e-05 - val_loss: 1.1963e-04\n",
      "Epoch 727/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5054e-05 - val_loss: 1.1831e-04\n",
      "Epoch 728/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4752e-05 - val_loss: 1.1806e-04\n",
      "Epoch 729/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4819e-05 - val_loss: 1.1507e-04\n",
      "Epoch 730/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.3652e-05 - val_loss: 1.1370e-04\n",
      "Epoch 731/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.3656e-05 - val_loss: 1.1425e-04\n",
      "Epoch 732/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5176e-05 - val_loss: 1.1207e-04\n",
      "Epoch 733/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4443e-05 - val_loss: 1.1366e-04\n",
      "Epoch 734/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.5376e-05 - val_loss: 1.1464e-04\n",
      "Epoch 735/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4802e-05 - val_loss: 1.1622e-04\n",
      "Epoch 736/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.6024e-05 - val_loss: 1.1391e-04\n",
      "Epoch 737/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5906e-05 - val_loss: 1.1506e-04\n",
      "Epoch 738/1000\n",
      "100/100 [==============================] - 0s 71us/step - loss: 7.5676e-05 - val_loss: 1.1617e-04\n",
      "Epoch 739/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 70us/step - loss: 7.5558e-05 - val_loss: 1.1280e-04\n",
      "Epoch 740/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5170e-05 - val_loss: 1.1371e-04\n",
      "Epoch 741/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4665e-05 - val_loss: 1.1479e-04\n",
      "Epoch 742/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4606e-05 - val_loss: 1.1405e-04\n",
      "Epoch 743/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.5215e-05 - val_loss: 1.1632e-04\n",
      "Epoch 744/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.3996e-05 - val_loss: 1.1785e-04\n",
      "Epoch 745/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4010e-05 - val_loss: 1.1867e-04\n",
      "Epoch 746/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.5076e-05 - val_loss: 1.1869e-04\n",
      "Epoch 747/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.5621e-05 - val_loss: 1.2313e-04\n",
      "Epoch 748/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4860e-05 - val_loss: 1.2299e-04\n",
      "Epoch 749/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5756e-05 - val_loss: 1.2277e-04\n",
      "Epoch 750/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5565e-05 - val_loss: 1.2166e-04\n",
      "Epoch 751/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5128e-05 - val_loss: 1.2003e-04\n",
      "Epoch 752/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.6146e-05 - val_loss: 1.2117e-04\n",
      "Epoch 753/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.6270e-05 - val_loss: 1.2044e-04\n",
      "Epoch 754/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4086e-05 - val_loss: 1.1836e-04\n",
      "Epoch 755/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5926e-05 - val_loss: 1.1976e-04\n",
      "Epoch 756/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4267e-05 - val_loss: 1.2038e-04\n",
      "Epoch 757/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5645e-05 - val_loss: 1.1980e-04\n",
      "Epoch 758/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4682e-05 - val_loss: 1.2230e-04\n",
      "Epoch 759/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5359e-05 - val_loss: 1.2281e-04\n",
      "Epoch 760/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.6911e-05 - val_loss: 1.1669e-04\n",
      "Epoch 761/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4794e-05 - val_loss: 1.1407e-04\n",
      "Epoch 762/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4934e-05 - val_loss: 1.1475e-04\n",
      "Epoch 763/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5374e-05 - val_loss: 1.1491e-04\n",
      "Epoch 764/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4741e-05 - val_loss: 1.1459e-04\n",
      "Epoch 765/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4215e-05 - val_loss: 1.1424e-04\n",
      "Epoch 766/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5694e-05 - val_loss: 1.1401e-04\n",
      "Epoch 767/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4951e-05 - val_loss: 1.1740e-04\n",
      "Epoch 768/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4575e-05 - val_loss: 1.1662e-04\n",
      "Epoch 769/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5098e-05 - val_loss: 1.1340e-04\n",
      "Epoch 770/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5617e-05 - val_loss: 1.1258e-04\n",
      "Epoch 771/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4487e-05 - val_loss: 1.1491e-04\n",
      "Epoch 772/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.3958e-05 - val_loss: 1.1642e-04\n",
      "Epoch 773/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6123e-05 - val_loss: 1.1775e-04\n",
      "Epoch 774/1000\n",
      "100/100 [==============================] - 0s 122us/step - loss: 7.6008e-05 - val_loss: 1.1497e-04\n",
      "Epoch 775/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5155e-05 - val_loss: 1.1834e-04\n",
      "Epoch 776/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4430e-05 - val_loss: 1.1790e-04\n",
      "Epoch 777/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4595e-05 - val_loss: 1.1993e-04\n",
      "Epoch 778/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5787e-05 - val_loss: 1.1726e-04\n",
      "Epoch 779/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.3913e-05 - val_loss: 1.1605e-04\n",
      "Epoch 780/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4570e-05 - val_loss: 1.1835e-04\n",
      "Epoch 781/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 7.6194e-05 - val_loss: 1.2190e-04\n",
      "Epoch 782/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.7442e-05 - val_loss: 1.2202e-04\n",
      "Epoch 783/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.6254e-05 - val_loss: 1.1706e-04\n",
      "Epoch 784/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 7.4891e-05 - val_loss: 1.1832e-04\n",
      "Epoch 785/1000\n",
      "100/100 [==============================] - 0s 91us/step - loss: 7.4403e-05 - val_loss: 1.1997e-04\n",
      "Epoch 786/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5370e-05 - val_loss: 1.1943e-04\n",
      "Epoch 787/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.7285e-05 - val_loss: 1.1841e-04\n",
      "Epoch 788/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.3992e-05 - val_loss: 1.1747e-04\n",
      "Epoch 789/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.3395e-05 - val_loss: 1.1745e-04\n",
      "Epoch 790/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4887e-05 - val_loss: 1.1693e-04\n",
      "Epoch 791/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5654e-05 - val_loss: 1.1305e-04\n",
      "Epoch 792/1000\n",
      "100/100 [==============================] - 0s 91us/step - loss: 7.5529e-05 - val_loss: 1.1397e-04\n",
      "Epoch 793/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4354e-05 - val_loss: 1.1666e-04\n",
      "Epoch 794/1000\n",
      "100/100 [==============================] - 0s 105us/step - loss: 7.4133e-05 - val_loss: 1.1802e-04\n",
      "Epoch 795/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.3791e-05 - val_loss: 1.2067e-04\n",
      "Epoch 796/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.5714e-05 - val_loss: 1.1743e-04\n",
      "Epoch 797/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4856e-05 - val_loss: 1.2034e-04\n",
      "Epoch 798/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.5365e-05 - val_loss: 1.1787e-04\n",
      "Epoch 799/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.5503e-05 - val_loss: 1.1680e-04\n",
      "Epoch 800/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4531e-05 - val_loss: 1.1545e-04\n",
      "Epoch 801/1000\n",
      "100/100 [==============================] - 0s 81us/step - loss: 7.6591e-05 - val_loss: 1.1459e-04\n",
      "Epoch 802/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5784e-05 - val_loss: 1.1569e-04\n",
      "Epoch 803/1000\n",
      "100/100 [==============================] - 0s 78us/step - loss: 7.5119e-05 - val_loss: 1.1603e-04\n",
      "Epoch 804/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.5248e-05 - val_loss: 1.1391e-04\n",
      "Epoch 805/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.5229e-05 - val_loss: 1.1804e-04\n",
      "Epoch 806/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4929e-05 - val_loss: 1.1668e-04\n",
      "Epoch 807/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.5576e-05 - val_loss: 1.1385e-04\n",
      "Epoch 808/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4977e-05 - val_loss: 1.1547e-04\n",
      "Epoch 809/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4642e-05 - val_loss: 1.1454e-04\n",
      "Epoch 810/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4711e-05 - val_loss: 1.1658e-04\n",
      "Epoch 811/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 100us/step - loss: 7.4972e-05 - val_loss: 1.1841e-04\n",
      "Epoch 812/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4247e-05 - val_loss: 1.1766e-04\n",
      "Epoch 813/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4374e-05 - val_loss: 1.1744e-04\n",
      "Epoch 814/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.5463e-05 - val_loss: 1.1946e-04\n",
      "Epoch 815/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4038e-05 - val_loss: 1.1929e-04\n",
      "Epoch 816/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4431e-05 - val_loss: 1.2133e-04\n",
      "Epoch 817/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4916e-05 - val_loss: 1.1832e-04\n",
      "Epoch 818/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4818e-05 - val_loss: 1.1939e-04\n",
      "Epoch 819/1000\n",
      "100/100 [==============================] - 0s 119us/step - loss: 7.4202e-05 - val_loss: 1.1991e-04\n",
      "Epoch 820/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5270e-05 - val_loss: 1.2028e-04\n",
      "Epoch 821/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5513e-05 - val_loss: 1.1770e-04\n",
      "Epoch 822/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6027e-05 - val_loss: 1.1533e-04\n",
      "Epoch 823/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6377e-05 - val_loss: 1.1575e-04\n",
      "Epoch 824/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4827e-05 - val_loss: 1.1574e-04\n",
      "Epoch 825/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6149e-05 - val_loss: 1.1407e-04\n",
      "Epoch 826/1000\n",
      "100/100 [==============================] - 0s 117us/step - loss: 7.5568e-05 - val_loss: 1.1450e-04\n",
      "Epoch 827/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5042e-05 - val_loss: 1.1430e-04\n",
      "Epoch 828/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4703e-05 - val_loss: 1.1314e-04\n",
      "Epoch 829/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5906e-05 - val_loss: 1.1280e-04\n",
      "Epoch 830/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4665e-05 - val_loss: 1.1588e-04\n",
      "Epoch 831/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6195e-05 - val_loss: 1.1790e-04\n",
      "Epoch 832/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.6615e-05 - val_loss: 1.1889e-04\n",
      "Epoch 833/1000\n",
      "100/100 [==============================] - 0s 113us/step - loss: 7.5320e-05 - val_loss: 1.1766e-04\n",
      "Epoch 834/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4508e-05 - val_loss: 1.1456e-04\n",
      "Epoch 835/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5006e-05 - val_loss: 1.1608e-04\n",
      "Epoch 836/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4093e-05 - val_loss: 1.1780e-04\n",
      "Epoch 837/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4193e-05 - val_loss: 1.1665e-04\n",
      "Epoch 838/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5119e-05 - val_loss: 1.1612e-04\n",
      "Epoch 839/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5267e-05 - val_loss: 1.1761e-04\n",
      "Epoch 840/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5593e-05 - val_loss: 1.1943e-04\n",
      "Epoch 841/1000\n",
      "100/100 [==============================] - 0s 109us/step - loss: 7.4158e-05 - val_loss: 1.1892e-04\n",
      "Epoch 842/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5416e-05 - val_loss: 1.1763e-04\n",
      "Epoch 843/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6027e-05 - val_loss: 1.1773e-04\n",
      "Epoch 844/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4237e-05 - val_loss: 1.1730e-04\n",
      "Epoch 845/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4774e-05 - val_loss: 1.1522e-04\n",
      "Epoch 846/1000\n",
      "100/100 [==============================] - 0s 150us/step - loss: 7.5022e-05 - val_loss: 1.1590e-04\n",
      "Epoch 847/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5613e-05 - val_loss: 1.1901e-04\n",
      "Epoch 848/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4763e-05 - val_loss: 1.2054e-04\n",
      "Epoch 849/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4473e-05 - val_loss: 1.1612e-04\n",
      "Epoch 850/1000\n",
      "100/100 [==============================] - 0s 118us/step - loss: 7.5263e-05 - val_loss: 1.1759e-04\n",
      "Epoch 851/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6536e-05 - val_loss: 1.1550e-04\n",
      "Epoch 852/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.3887e-05 - val_loss: 1.1563e-04\n",
      "Epoch 853/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4318e-05 - val_loss: 1.1534e-04\n",
      "Epoch 854/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6152e-05 - val_loss: 1.1687e-04\n",
      "Epoch 855/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6417e-05 - val_loss: 1.1451e-04\n",
      "Epoch 856/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4910e-05 - val_loss: 1.1845e-04\n",
      "Epoch 857/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 7.5273e-05 - val_loss: 1.2238e-04\n",
      "Epoch 858/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4726e-05 - val_loss: 1.2042e-04\n",
      "Epoch 859/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5261e-05 - val_loss: 1.1795e-04\n",
      "Epoch 860/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5329e-05 - val_loss: 1.1642e-04\n",
      "Epoch 861/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4307e-05 - val_loss: 1.1738e-04\n",
      "Epoch 862/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4230e-05 - val_loss: 1.1334e-04\n",
      "Epoch 863/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4177e-05 - val_loss: 1.1606e-04\n",
      "Epoch 864/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5027e-05 - val_loss: 1.1205e-04\n",
      "Epoch 865/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4759e-05 - val_loss: 1.1401e-04\n",
      "Epoch 866/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4897e-05 - val_loss: 1.1555e-04\n",
      "Epoch 867/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.4129e-05 - val_loss: 1.1513e-04\n",
      "Epoch 868/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.3783e-05 - val_loss: 1.1513e-04\n",
      "Epoch 869/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.3389e-05 - val_loss: 1.1728e-04\n",
      "Epoch 870/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.5108e-05 - val_loss: 1.2006e-04\n",
      "Epoch 871/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.6391e-05 - val_loss: 1.2011e-04\n",
      "Epoch 872/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.5187e-05 - val_loss: 1.1777e-04\n",
      "Epoch 873/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4692e-05 - val_loss: 1.1843e-04\n",
      "Epoch 874/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5135e-05 - val_loss: 1.1439e-04\n",
      "Epoch 875/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5500e-05 - val_loss: 1.1551e-04\n",
      "Epoch 876/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.6222e-05 - val_loss: 1.1630e-04\n",
      "Epoch 877/1000\n",
      "100/100 [==============================] - 0s 101us/step - loss: 7.5001e-05 - val_loss: 1.1907e-04\n",
      "Epoch 878/1000\n",
      "100/100 [==============================] - 0s 89us/step - loss: 7.3763e-05 - val_loss: 1.1752e-04\n",
      "Epoch 879/1000\n",
      "100/100 [==============================] - 0s 91us/step - loss: 7.5182e-05 - val_loss: 1.1377e-04\n",
      "Epoch 880/1000\n",
      "100/100 [==============================] - 0s 91us/step - loss: 7.4434e-05 - val_loss: 1.1185e-04\n",
      "Epoch 881/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.7994e-05 - val_loss: 1.1429e-04\n",
      "Epoch 882/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4912e-05 - val_loss: 1.1321e-04\n",
      "Epoch 883/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 91us/step - loss: 7.5135e-05 - val_loss: 1.1302e-04\n",
      "Epoch 884/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.6013e-05 - val_loss: 1.1235e-04\n",
      "Epoch 885/1000\n",
      "100/100 [==============================] - 0s 80us/step - loss: 7.4708e-05 - val_loss: 1.1555e-04\n",
      "Epoch 886/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.4686e-05 - val_loss: 1.1699e-04\n",
      "Epoch 887/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.4801e-05 - val_loss: 1.1768e-04\n",
      "Epoch 888/1000\n",
      "100/100 [==============================] - 0s 70us/step - loss: 7.5709e-05 - val_loss: 1.1633e-04\n",
      "Epoch 889/1000\n",
      "100/100 [==============================] - 0s 60us/step - loss: 7.5105e-05 - val_loss: 1.1588e-04\n",
      "Epoch 890/1000\n",
      "100/100 [==============================] - 0s 79us/step - loss: 7.4910e-05 - val_loss: 1.1405e-04\n",
      "Epoch 891/1000\n",
      "100/100 [==============================] - 0s 90us/step - loss: 7.4500e-05 - val_loss: 1.1493e-04\n",
      "Epoch 892/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5812e-05 - val_loss: 1.1362e-04\n",
      "Epoch 893/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5858e-05 - val_loss: 1.1559e-04\n",
      "Epoch 894/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4213e-05 - val_loss: 1.1475e-04\n",
      "Epoch 895/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4950e-05 - val_loss: 1.1569e-04\n",
      "Epoch 896/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5517e-05 - val_loss: 1.1254e-04\n",
      "Epoch 897/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4400e-05 - val_loss: 1.1400e-04\n",
      "Epoch 898/1000\n",
      "100/100 [==============================] - 0s 115us/step - loss: 7.5167e-05 - val_loss: 1.1563e-04\n",
      "Epoch 899/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6069e-05 - val_loss: 1.1625e-04\n",
      "Epoch 900/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.3658e-05 - val_loss: 1.1838e-04\n",
      "Epoch 901/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 7.5385e-05 - val_loss: 1.1711e-04\n",
      "Epoch 902/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4972e-05 - val_loss: 1.1895e-04\n",
      "Epoch 903/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5621e-05 - val_loss: 1.2085e-04\n",
      "Epoch 904/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.8282e-05 - val_loss: 1.1946e-04\n",
      "Epoch 905/1000\n",
      "100/100 [==============================] - 0s 101us/step - loss: 7.4002e-05 - val_loss: 1.1779e-04\n",
      "Epoch 906/1000\n",
      "100/100 [==============================] - 0s 114us/step - loss: 7.4244e-05 - val_loss: 1.1951e-04\n",
      "Epoch 907/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4681e-05 - val_loss: 1.1719e-04\n",
      "Epoch 908/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4464e-05 - val_loss: 1.1934e-04\n",
      "Epoch 909/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.7235e-05 - val_loss: 1.1963e-04\n",
      "Epoch 910/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4342e-05 - val_loss: 1.1890e-04\n",
      "Epoch 911/1000\n",
      "100/100 [==============================] - 0s 119us/step - loss: 7.5851e-05 - val_loss: 1.1924e-04\n",
      "Epoch 912/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6159e-05 - val_loss: 1.2025e-04\n",
      "Epoch 913/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5557e-05 - val_loss: 1.1604e-04\n",
      "Epoch 914/1000\n",
      "100/100 [==============================] - 0s 101us/step - loss: 7.4666e-05 - val_loss: 1.1564e-04\n",
      "Epoch 915/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 7.5823e-05 - val_loss: 1.1396e-04\n",
      "Epoch 916/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4733e-05 - val_loss: 1.1348e-04\n",
      "Epoch 917/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4876e-05 - val_loss: 1.1456e-04\n",
      "Epoch 918/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6373e-05 - val_loss: 1.1450e-04\n",
      "Epoch 919/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.3845e-05 - val_loss: 1.1451e-04\n",
      "Epoch 920/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4352e-05 - val_loss: 1.1591e-04\n",
      "Epoch 921/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 7.3939e-05 - val_loss: 1.1280e-04\n",
      "Epoch 922/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4772e-05 - val_loss: 1.1534e-04\n",
      "Epoch 923/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5117e-05 - val_loss: 1.1608e-04\n",
      "Epoch 924/1000\n",
      "100/100 [==============================] - 0s 132us/step - loss: 7.4293e-05 - val_loss: 1.1606e-04\n",
      "Epoch 925/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5247e-05 - val_loss: 1.1868e-04\n",
      "Epoch 926/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6554e-05 - val_loss: 1.1861e-04\n",
      "Epoch 927/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4466e-05 - val_loss: 1.2053e-04\n",
      "Epoch 928/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.7732e-05 - val_loss: 1.2210e-04\n",
      "Epoch 929/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5460e-05 - val_loss: 1.2074e-04\n",
      "Epoch 930/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4248e-05 - val_loss: 1.1524e-04\n",
      "Epoch 931/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5227e-05 - val_loss: 1.1901e-04\n",
      "Epoch 932/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5285e-05 - val_loss: 1.1786e-04\n",
      "Epoch 933/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4166e-05 - val_loss: 1.1743e-04\n",
      "Epoch 934/1000\n",
      "100/100 [==============================] - 0s 109us/step - loss: 7.5022e-05 - val_loss: 1.1734e-04\n",
      "Epoch 935/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6262e-05 - val_loss: 1.1765e-04\n",
      "Epoch 936/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4907e-05 - val_loss: 1.1476e-04\n",
      "Epoch 937/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5085e-05 - val_loss: 1.1653e-04\n",
      "Epoch 938/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4948e-05 - val_loss: 1.1666e-04\n",
      "Epoch 939/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4594e-05 - val_loss: 1.1772e-04\n",
      "Epoch 940/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4062e-05 - val_loss: 1.1700e-04\n",
      "Epoch 941/1000\n",
      "100/100 [==============================] - 0s 101us/step - loss: 7.5086e-05 - val_loss: 1.1949e-04\n",
      "Epoch 942/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5815e-05 - val_loss: 1.2009e-04\n",
      "Epoch 943/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4637e-05 - val_loss: 1.1897e-04\n",
      "Epoch 944/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5448e-05 - val_loss: 1.2109e-04\n",
      "Epoch 945/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.3808e-05 - val_loss: 1.1603e-04\n",
      "Epoch 946/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5111e-05 - val_loss: 1.1717e-04\n",
      "Epoch 947/1000\n",
      "100/100 [==============================] - 0s 111us/step - loss: 7.4579e-05 - val_loss: 1.1877e-04\n",
      "Epoch 948/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4717e-05 - val_loss: 1.1975e-04\n",
      "Epoch 949/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5565e-05 - val_loss: 1.1994e-04\n",
      "Epoch 950/1000\n",
      "100/100 [==============================] - 0s 119us/step - loss: 7.4597e-05 - val_loss: 1.1678e-04\n",
      "Epoch 951/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6078e-05 - val_loss: 1.1373e-04\n",
      "Epoch 952/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.6071e-05 - val_loss: 1.1433e-04\n",
      "Epoch 953/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5156e-05 - val_loss: 1.1588e-04\n",
      "Epoch 954/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.3614e-05 - val_loss: 1.1494e-04\n",
      "Epoch 955/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 109us/step - loss: 7.5005e-05 - val_loss: 1.1807e-04\n",
      "Epoch 956/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4171e-05 - val_loss: 1.1864e-04\n",
      "Epoch 957/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5310e-05 - val_loss: 1.1999e-04\n",
      "Epoch 958/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5063e-05 - val_loss: 1.2018e-04\n",
      "Epoch 959/1000\n",
      "100/100 [==============================] - 0s 121us/step - loss: 7.6854e-05 - val_loss: 1.1700e-04\n",
      "Epoch 960/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4440e-05 - val_loss: 1.1920e-04\n",
      "Epoch 961/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4322e-05 - val_loss: 1.1956e-04\n",
      "Epoch 962/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4762e-05 - val_loss: 1.1983e-04\n",
      "Epoch 963/1000\n",
      "100/100 [==============================] - 0s 131us/step - loss: 7.5501e-05 - val_loss: 1.2187e-04\n",
      "Epoch 964/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4480e-05 - val_loss: 1.1895e-04\n",
      "Epoch 965/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.6066e-05 - val_loss: 1.1791e-04\n",
      "Epoch 966/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4124e-05 - val_loss: 1.1720e-04\n",
      "Epoch 967/1000\n",
      "100/100 [==============================] - 0s 119us/step - loss: 7.4959e-05 - val_loss: 1.1546e-04\n",
      "Epoch 968/1000\n",
      "100/100 [==============================] - 0s 113us/step - loss: 7.4105e-05 - val_loss: 1.1530e-04\n",
      "Epoch 969/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4874e-05 - val_loss: 1.1381e-04\n",
      "Epoch 970/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5792e-05 - val_loss: 1.1285e-04\n",
      "Epoch 971/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5543e-05 - val_loss: 1.1442e-04\n",
      "Epoch 972/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.4139e-05 - val_loss: 1.1491e-04\n",
      "Epoch 973/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4299e-05 - val_loss: 1.1249e-04\n",
      "Epoch 974/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5028e-05 - val_loss: 1.0928e-04\n",
      "Epoch 975/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4822e-05 - val_loss: 1.1133e-04\n",
      "Epoch 976/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5726e-05 - val_loss: 1.1073e-04\n",
      "Epoch 977/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4553e-05 - val_loss: 1.1200e-04\n",
      "Epoch 978/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5198e-05 - val_loss: 1.1221e-04\n",
      "Epoch 979/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4894e-05 - val_loss: 1.0981e-04\n",
      "Epoch 980/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4600e-05 - val_loss: 1.1264e-04\n",
      "Epoch 981/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4137e-05 - val_loss: 1.1687e-04\n",
      "Epoch 982/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4855e-05 - val_loss: 1.1570e-04\n",
      "Epoch 983/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4806e-05 - val_loss: 1.1218e-04\n",
      "Epoch 984/1000\n",
      "100/100 [==============================] - 0s 139us/step - loss: 7.4031e-05 - val_loss: 1.1590e-04\n",
      "Epoch 985/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5776e-05 - val_loss: 1.1586e-04\n",
      "Epoch 986/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5161e-05 - val_loss: 1.1862e-04\n",
      "Epoch 987/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5304e-05 - val_loss: 1.1549e-04\n",
      "Epoch 988/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.5395e-05 - val_loss: 1.1546e-04\n",
      "Epoch 989/1000\n",
      "100/100 [==============================] - 0s 108us/step - loss: 7.4218e-05 - val_loss: 1.1540e-04\n",
      "Epoch 990/1000\n",
      "100/100 [==============================] - 0s 130us/step - loss: 7.5334e-05 - val_loss: 1.1672e-04\n",
      "Epoch 991/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5495e-05 - val_loss: 1.1820e-04\n",
      "Epoch 992/1000\n",
      "100/100 [==============================] - 0s 100us/step - loss: 7.5102e-05 - val_loss: 1.1823e-04\n",
      "Epoch 993/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5700e-05 - val_loss: 1.1858e-04\n",
      "Epoch 994/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4936e-05 - val_loss: 1.1702e-04\n",
      "Epoch 995/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4156e-05 - val_loss: 1.1892e-04\n",
      "Epoch 996/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5528e-05 - val_loss: 1.2024e-04\n",
      "Epoch 997/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4476e-05 - val_loss: 1.1982e-04\n",
      "Epoch 998/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.4573e-05 - val_loss: 1.1660e-04\n",
      "Epoch 999/1000\n",
      "100/100 [==============================] - 0s 120us/step - loss: 7.4658e-05 - val_loss: 1.1442e-04\n",
      "Epoch 1000/1000\n",
      "100/100 [==============================] - 0s 110us/step - loss: 7.5715e-05 - val_loss: 1.1318e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19802477b00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x = x_train, y = y_train,\n",
    "    shuffle = True,\n",
    "    epochs = 1000,\n",
    "    batch_size = 30,\n",
    "    validation_data = (x_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1980259a518>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.scatter(x_train, y_train)\n",
    "\n",
    "xxx = np.linspace(-3, 3, 50)\n",
    "pl.plot(xxx, model.predict(xxx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
